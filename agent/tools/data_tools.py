import pandas as pd
import numpy as np
import json
import duckdb
import logging
from typing import Any, Dict, List, Optional, Union
import os
from pathlib import Path
import PyPDF2
import fitz  # PyMuPDF
from openpyxl import load_workbook

logger = logging.getLogger(__name__)

class DataProcessor:
    """Tool for data loading, processing, and SQL operations"""
    
    def __init__(self):
        self.duckdb_conn = duckdb.connect(':memory:')
        # Install necessary extensions
        try:
            self.duckdb_conn.execute("INSTALL httpfs")
            self.duckdb_conn.execute("LOAD httpfs")
            self.duckdb_conn.execute("INSTALL parquet")
            self.duckdb_conn.execute("LOAD parquet")
        except:
            pass  # Extensions might already be installed
    
    def load_file(self, file_path: str) -> Any:
        """
        Load data from various file formats
        
        Args:
            file_path: Path to the file to load
            
        Returns:
            Loaded data (DataFrame for structured data, dict for JSON, etc.)
        """
        file_path = Path(file_path)
        extension = file_path.suffix.lower()
        
        logger.info(f"Loading file: {file_path} (type: {extension})")
        
        try:
            if extension == '.csv':
                return self._load_csv(file_path)
            elif extension in ['.xlsx', '.xls']:
                return self._load_excel(file_path)
            elif extension == '.json':
                return self._load_json(file_path)
            elif extension == '.parquet':
                return self._load_parquet(file_path)
            elif extension == '.pdf':
                return self._load_pdf(file_path)
            elif extension == '.txt':
                return self._load_text(file_path)
            else:
                # Try to load as text by default
                return self._load_text(file_path)
                
        except Exception as e:
            logger.error(f"Failed to load file {file_path}: {e}")
            raise
    
    def _load_csv(self, file_path: Path) -> pd.DataFrame:
        """Load CSV file with various encodings"""
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                logger.info(f"Loaded CSV with shape {df.shape} using {encoding}")
                return df
            except UnicodeDecodeError:
                continue
            except Exception as e:
                if encoding == encodings[-1]:  # Last encoding
                    raise e
                continue
        
        raise ValueError("Could not load CSV with any supported encoding")
    
    def _load_excel(self, file_path: Path) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
        """Load Excel file"""
        try:
            # Load all sheets
            sheets = pd.read_excel(file_path, sheet_name=None)
            
            if len(sheets) == 1:
                # Return single DataFrame if only one sheet
                return list(sheets.values())[0]
            else:
                # Return dict of DataFrames if multiple sheets
                return sheets
                
        except Exception as e:
            logger.error(f"Failed to load Excel file: {e}")
            raise
    
    def _load_json(self, file_path: Path) -> Union[Dict, List]:
        """Load JSON file"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_parquet(self, file_path: Path) -> pd.DataFrame:
        """Load Parquet file"""
        return pd.read_parquet(file_path)
    
    def _load_pdf(self, file_path: Path) -> Dict[str, Any]:
        """Extract text from PDF file"""
        result = {
            'text': '',
            'pages': [],
            'metadata': {}
        }
        
        try:
            # Use PyMuPDF for better text extraction
            doc = fitz.open(file_path)
            
            result['metadata'] = {
                'page_count': len(doc),
                'title': doc.metadata.get('title', ''),
                'author': doc.metadata.get('author', ''),
                'subject': doc.metadata.get('subject', '')
            }
            
            all_text = []
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text()
                all_text.append(page_text)
                result['pages'].append({
                    'page_number': page_num + 1,
                    'text': page_text
                })
            
            result['text'] = '\n'.join(all_text)
            doc.close()
            
        except Exception as e:
            logger.error(f"Failed to extract PDF text: {e}")
            # Fallback to PyPDF2
            try:
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text_parts = []
                    
                    for page_num, page in enumerate(reader.pages):
                        page_text = page.extract_text()
                        text_parts.append(page_text)
                        result['pages'].append({
                            'page_number': page_num + 1,
                            'text': page_text
                        })
                    
                    result['text'] = '\n'.join(text_parts)
                    result['metadata']['page_count'] = len(reader.pages)
                    
            except Exception as e2:
                logger.error(f"PyPDF2 also failed: {e2}")
                raise e
        
        return result
    
    def _load_text(self, file_path: Path) -> str:
        """Load text file"""
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        
        raise ValueError("Could not load text file with any supported encoding")
    
    def execute_sql_query(self, query: str) -> pd.DataFrame:
        """
        Execute SQL query using DuckDB
        
        Args:
            query: SQL query to execute
            
        Returns:
            Query results as DataFrame
        """
        try:
            logger.info(f"Executing SQL query: {query[:100]}...")
            
            # Execute query and return as DataFrame
            result = self.duckdb_conn.execute(query).df()
            
            logger.info(f"Query returned {len(result)} rows, {len(result.columns)} columns")
            return result
            
        except Exception as e:
            logger.error(f"SQL query failed: {e}")
            raise
    
    def register_dataframe(self, df: pd.DataFrame, table_name: str):
        """Register a DataFrame as a table in DuckDB"""
        try:
            self.duckdb_conn.register(table_name, df)
            logger.info(f"Registered DataFrame as table '{table_name}'")
        except Exception as e:
            logger.error(f"Failed to register DataFrame: {e}")
            raise
    
    def create_table_from_data(self, data: Any, table_name: str):
        """Create a table from various data types"""
        if isinstance(data, pd.DataFrame):
            self.register_dataframe(data, table_name)
        elif isinstance(data, list):
            df = pd.DataFrame(data)
            self.register_dataframe(df, table_name)
        elif isinstance(data, dict):
            if all(isinstance(v, list) for v in data.values()):
                df = pd.DataFrame(data)
                self.register_dataframe(df, table_name)
            else:
                # Convert dict to single-row DataFrame
                df = pd.DataFrame([data])
                self.register_dataframe(df, table_name)
        else:
            raise ValueError(f"Cannot create table from data type: {type(data)}")
    
    def get_table_info(self, table_name: str) -> Dict[str, Any]:
        """Get information about a table"""
        try:
            # Get column information
            columns_query = f"DESCRIBE {table_name}"
            columns_info = self.duckdb_conn.execute(columns_query).df()
            
            # Get row count
            count_query = f"SELECT COUNT(*) as row_count FROM {table_name}"
            row_count = self.duckdb_conn.execute(count_query).fetchone()[0]
            
            # Get sample data
            sample_query = f"SELECT * FROM {table_name} LIMIT 5"
            sample_data = self.duckdb_conn.execute(sample_query).df()
            
            return {
                'table_name': table_name,
                'columns': columns_info.to_dict('records'),
                'row_count': row_count,
                'sample_data': sample_data.to_dict('records')
            }
            
        except Exception as e:
            logger.error(f"Failed to get table info for {table_name}: {e}")
            raise
    
    def clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean and prepare DataFrame for analysis"""
        clean_df = df.copy()
        
        # Remove completely empty rows and columns
        clean_df = clean_df.dropna(how='all').dropna(axis=1, how='all')
        
        # Clean column names
        clean_df.columns = [str(col).strip().replace(' ', '_').replace('.', '_') 
                           for col in clean_df.columns]
        
        # Try to infer and convert data types
        for col in clean_df.columns:
            if clean_df[col].dtype == 'object':
                # Try to convert to numeric
                numeric_series = pd.to_numeric(clean_df[col], errors='coerce')
                if not numeric_series.isna().all():
                    # If more than 50% of values can be converted to numeric, do it
                    if numeric_series.notna().sum() / len(numeric_series) > 0.5:
                        clean_df[col] = numeric_series
                
                # Try to convert to datetime
                try:
                    if not clean_df[col].isna().all():
                        datetime_series = pd.to_datetime(clean_df[col], errors='coerce', infer_datetime_format=True)
                        if datetime_series.notna().sum() / len(datetime_series) > 0.5:
                            clean_df[col] = datetime_series
                except:
                    pass
        
        return clean_df
    
    def get_data_summary(self, data: Any) -> Dict[str, Any]:
        """Get summary statistics for data"""
        if isinstance(data, pd.DataFrame):
            return {
                'type': 'dataframe',
                'shape': data.shape,
                'columns': list(data.columns),
                'dtypes': data.dtypes.to_dict(),
                'null_counts': data.isnull().sum().to_dict(),
                'numeric_summary': data.describe().to_dict() if len(data.select_dtypes(include=[np.number]).columns) > 0 else {},
                'sample_data': data.head().to_dict('records')
            }
        elif isinstance(data, dict):
            return {
                'type': 'dictionary',
                'keys': list(data.keys()),
                'sample': {k: str(v)[:100] + '...' if len(str(v)) > 100 else v 
                          for k, v in list(data.items())[:5]}
            }
        elif isinstance(data, list):
            return {
                'type': 'list',
                'length': len(data),
                'sample': data[:5] if len(data) > 5 else data
            }
        else:
            return {
                'type': str(type(data)),
                'value': str(data)[:200] + '...' if len(str(data)) > 200 else str(data)
            }
    
    def close(self):
        """Close DuckDB connection"""
        if self.duckdb_conn:
            self.duckdb_conn.close()